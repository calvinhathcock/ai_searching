# ai_searching
### Introduction

The set of problems that follow consist of various implementations of state space searching.  Given a state space abstracted in the form of a tree or graph, searching is the process of exploring said graph until a defined goal is met. There are multiple strategies of searching that can be implemented, in this report, we will be focusing on uninformed search, informed search, and local search. Two example problems will be used to implement these search strategies. The first of which is to simply find a path from one point in a grid to another, the second is known as the N-Queens problem. Each search strategy will be analyzed and the pros and cons of each will be discussed.

### Classical Search

The first problem to be implemented is formulated by a two-dimensional grid. An agent is tasked with finding a path from one starting position to a different goal position within the grid. Each position in the grid is represented by a numeric value indicating the cost to move to that position. Positions with a value of zero represent a wall which cannot be traversed. The agent can move vertically and horizontally, but not diagonally. 
State representation: A square two dimensional array of integers. This array can be various sizes. Each position has an integer value that represents its step cost, 0 meaning the position is non-traversable. 
Actions: The list of actions moves the agent to a new position in the grid
Move right
Move left
Move up
Move down
Transition Model: The transition model accepts a state and an action, and returns a new state. For this problem, the transition model checks that the new state is within the bounds of the grid and that the position is not of value zero.
Goal test: The goal test will be checked after each action to see if the new position is equal to the goal. 
Path Cost: The past cost will be the sum of every node’s step cost that was visited until the goal node was found. 

### Uninformed Search

Uninformed search is  a search strategy that has no additional information about states beyond what is defined in the problem definition. All that it can do is generate successors and check if a given successor is the goal state. Different uninformed search strategies are primarily distinguished in the order in which successor nodes are expanded. The two uninformed search algorithms implemented here are Breadth First Search (BFS) and Depth First Search (DFS). The BFS algorithm is an instance of the general graph-search algorithm in which the shallowest unexpanded nodes are chosen for expansion. Given the first problem of finding a path from one point in a graph to another, you can imagine that given any starting position, BFS will tend to explore horizontally before moving vertically. DFS on the other hand, (as the name suggests) tends to explore depth before moving horizontally. These two algorithms are distinguished by the data structure in which unexplored nodes are stored. BFS uses a queue (First in, First out) data structure, and DFS uses a stack (Last in, First out). 
For this project, all the algorithms were implemented in Python. There is a script for each type of algorithm (uninformed, informed, local) and their necessary functions, a script for “helper” functions that can be used by any of the various search algorithms, a test script to run simulations, and a driver notebook that actually sets up and runs each algorithm and tests. 
As for the implementation of uninformed search algorithms, a “Node” class, “expand_node” function, “get_neighbors” function, and the actual search loop were all created.
Node: A class that represents a particular position on the grid.
get_neighbors: A function that returns all of the immediate neighbors of a given location and grid.
expand_node: A function that expands all of the neighbors of a given node. This function directly interacts with the search loop. It processes the closed and open lists and directly works with node objects. 
uninformed_search: Performs an uninformed search, either BFS or DFS. This is the heart of the uninformed search implementation. Given a starting node, the algorithm will expand the current node and add all of its neighbors to a list called the open list. Depending on the desired orientation of the search, this list will either be a queue(BFS) or a stack(DFS). Each iteration will get a new node from the open list and check to see if it is the goal node and if it is not, the node is expanded and then added to the closed list. The loop continues until there are no more nodes to check or until the goal node is reached. Once the loop is finished, the path to get to the goal node is generated by following all the parent nodes to the start position. 

We know that uninformed search algorithms are great at finding solutions, however they are not optimal. As the problem size grows, uninformed search will not do well since its time and space complexity are exponentially growing. 

Breadth first search
Time Complexity: O(bd) 
Space Complexity: O(bd)
Where b is the branching factor and d is the depth of the solution
Remember, breadth first search explores horizontally first so the worst case complexity is when the goal node is at a very deep depth.
Depth First Search
Time Complexity: O(bm)
Where b is the branching factor and m is the maximum depth of any node
Space Complexity: O(bm)
Since only the current path needs to be stored
Since depth first search always explores depth first (who would of guessed), it will almost always hit the deepest depth even when the goal is not at the deepest depth.

### Tests

The first four plots are of BFS and the next four are DFS. As expected, the uninformed search algorithms performed worse and worse as the problem size grew, however they were still very successful at actually finding solutions in the end, however long it may take. 

### Informed Search
Informed search is another type of classical search in which a path is returned as the solution. Unlike uninformed searches, informed search does have some more information beyond the problem definition. Most common method of attaining this additional information is through the use of heuristic functions. These are problem specific functions that provide heuristic information. For example, in our grid search problem a common heuristic could be the euclidean distance between a given position and the goal. The heuristic I will be implementing is the Manhattan distance. Beyond just having a heuristic value, different algorithms will utilize the value in different ways. Greedy search solely evaluates the heuristic value when choosing a node and takes nothing else into account. Whereas the A* algorithm uses both the heuristic value and the step cost to decide which node to traverse to. Greedy search is incomplete since it can get caught in infinite loops at local maximas and minimas. A* is optimal depending on the heuristic and can be complete in finite spaces. Once again, informed search algorithms decide where to traverse based on heuristic values to give them some insight on the best path.   
I implemented informed search with the A* algorithm. The implementation is very similar to uninformed search just with some added parameters tacked on. I created a subclass of our Node class that also contains properties for  g(n), h(n), and f(n). A less than method was overridden so that the node object could be compared in a heap. I created a heuristic function that calculates f(n). The expand_node function was slightly modified to take into account the heuristics and also new node properties. Lastly, the actual search loop was slightly modified to pop nodes from a heap.


Expectedly A* performed much better than its uninformed alternatives. The rate of change in which the number of nodes expanded was relatively linear, whereas they seemed exponential for the uninformed algorithms. 

### Local Search

The next type of search algorithm implemented is local search. The fundamental difference between local search and classical search is that local search does not store the path or even return a path as a solution. It only searches for the goal state and returns that. Because of this, local search has drastically smaller space complexity compared to classical search. Local search in some ways is similar to informed search since it uses either an object or cost function to aid making decisions. However, some local search algorithms operate completely randomly. 
   
In order to implement local search, a new problem needs to be formulated called the N-Queens problem. N-Queens is based off of the chess rules for queens which can move vertically, horizontally, and diagonally. Given N queens and an N by N chess board, the goal is to position all the queens so that none of them are attacking each other, meaning that none of them are in the same row, column, or diagonal. 
State representation: Any arrangement of N queens on an N by N board.
Actions: Move any queen to any space within its column
Transition model: Returns a board with the queen added to the specified position.
Goal test: None of the queens are attacking each other
Path cost: number of queens attacking each other in the new state

In order to solve this problem using local search, the simulated annealing algorithm was implemented. Simulated annealing is a very interesting algorithm that implements both randomization and probability that changes over time. When the algorithm first begins, it will randomly pick a successor node and then see if it is better than its predecessor, if so, then that node will be selected but if not it might select it based on a probability. As iterations go on, the probability of selecting these not as good nodes decreases at a specified decay rate. The algorithm stops when the goal node is found or when the probability hits a certain threshold. Note that this probability is represented as T for temperature (analogous to actual annealing).  The performance of the algorithm is affected by the specified decay rate and T threshold. The faster the decay and/or the higher the T threshold, the less iterations the algorithm will be allowed. The higher these values, the more iterations allowed. It is important to find a balance between these values so that the algorithm does not get cut off too early and so that it doesn’t go on longer than necessary. This algorithm was applied to the n-queens problem by using the number of attacking queens as the cost function and then randomly generating successor boards based on the current and then selecting a successor randomly. And again, this randomly selected successor is accepted if it has a lower cost and if not then depending on the probability. A few different simulations were tested to see the effectiveness of the algorithm. Ten total runs for each of the three different board sizes ranging 4,8,16 were completed and the average h-value of each board was recorded. 



Initial board:]<br>
[0, 0, 0, 1]<br>
[0, 0, 0, 1]<br>
[0, 1, 0, 0]<br>
[1, 0, 0, 0]<br>
h-value: 8<br>
Final board:<br>
[0, 1, 0, 0]<br>
[0, 0, 0, 1]<br>
[1, 0, 0, 0]<br>
[0, 0, 1, 0]<br>
h-value: 0<br>
---------------------------<br>
Average h-value of board size 4: 0.0<br>
---------------------------<br>
Initial board:<br>
[0, 1, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 1, 0, 0]<br>
[0, 0, 0, 1, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 1, 0]<br>
[0, 0, 0, 0, 0, 1, 0, 0]<br>
[0, 0, 1, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 1, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 1, 0]<br>
h-value: 20<br>
Final board:<br>
[1, 0, 0, 0, 0, 0, 0, 0] <br>
[0, 0, 1, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 1, 0, 0, 0]<br>
[0, 1, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 1]<br>
[1, 0, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 1, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 1, 0]<br>
h-value: 2<br>
---------------------------<br>
Average h-value of board size 8: 1.6<br>
---------------------------<br>
Initial board:<br>
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]<br>
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]<br>
[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]<br>
[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]<br>
h-value: 38<br>
Final board:<br>
[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br>
[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br>
[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]<br>
[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]<br>
[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]<br>
[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br>
[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]<br>
h-value: 6<br>
---------------------------<br>
Average h-value of board size 16: 8.0<br>
---------------------------<br>

As we can see, as the board size increases, the algorithm performs worse. It’s likely that many of the boards were completely solved but not always. This is due to the natural randomness of the algorithm. Tuning the parameters could affect the average h-values. 
